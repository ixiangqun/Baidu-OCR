#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç™¾åº¦OCRæ‰¹é‡å¤„ç†å™¨
ä½¿ç”¨ç™¾åº¦OCRé‡æ–°è¯†åˆ«æ‰€æœ‰å›¾ç‰‡
"""

import os
import time
from pathlib import Path
from datetime import datetime
from typing import List, Dict
from baidu_ocr_integration import BaiduOCRProcessor
import concurrent.futures
from tqdm import tqdm

class BaiduOCRBatchProcessor:
    """ç™¾åº¦OCRæ‰¹é‡å¤„ç†å™¨"""

    def __init__(self, api_key: str, secret_key: str):
        """åˆå§‹åŒ–å¤„ç†å™¨"""
        self.api_key = api_key
        self.secret_key = secret_key
        self.processor = BaiduOCRProcessor(api_key, secret_key)
        self.results = []
        self.processed_count = 0
        self.success_count = 0
        self.failed_count = 0

    def get_image_files(self, directory: str) -> List[str]:
        """è·å–ç›®å½•ä¸­çš„æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶"""
        path = Path(directory)
        image_files = []

        for ext in ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']:
            image_files.extend(path.glob(f"*{ext}"))
            image_files.extend(path.glob(f"*{ext.upper()}"))

        return [str(f) for f in sorted(image_files)]

    def process_single_image_safe(self, image_file: str, output_file: str) -> Dict:
        """å®‰å…¨å¤„ç†å•ä¸ªå›¾ç‰‡ï¼ŒåŒ…å«é”™è¯¯å¤„ç†"""
        try:
            start_time = time.time()

            # ä½¿ç”¨é«˜ç²¾åº¦æ¨¡å¼å¤„ç†
            success = self.processor.process_single_image(image_file, output_file, 'accurate')

            processing_time = time.time() - start_time

            if success:
                # è¯»å–å¤„ç†ç»“æœ
                try:
                    with open(output_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                    char_count = len(content)
                    word_count = len(content.split())
                except:
                    char_count = 0
                    word_count = 0

                self.success_count += 1
                return {
                    'success': True,
                    'image_file': image_file,
                    'output_file': output_file,
                    'processing_time': processing_time,
                    'char_count': char_count,
                    'word_count': word_count,
                    'error': None
                }
            else:
                self.failed_count += 1
                return {
                    'success': False,
                    'image_file': image_file,
                    'output_file': output_file,
                    'processing_time': processing_time,
                    'char_count': 0,
                    'word_count': 0,
                    'error': 'ç™¾åº¦OCRå¤„ç†å¤±è´¥'
                }

        except Exception as e:
            self.failed_count += 1
            return {
                'success': False,
                'image_file': image_file,
                'output_file': output_file,
                'processing_time': 0,
                'char_count': 0,
                'word_count': 0,
                'error': str(e)
            }

    def process_batch(self, image_dir: str, output_dir: str, max_workers: int = 3) -> Dict:
        """æ‰¹é‡å¤„ç†å›¾ç‰‡"""
        print("ğŸš€ å¼€å§‹ç™¾åº¦OCRæ‰¹é‡å¤„ç†")
        print("=" * 60)
        print(f"ğŸ“ å›¾ç‰‡ç›®å½•: {image_dir}")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        print(f"ğŸ”„ å¹¶å‘æ•°: {max_workers}")

        # è·å–å›¾ç‰‡æ–‡ä»¶
        image_files = self.get_image_files(image_dir)

        if not image_files:
            print("âŒ æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
            return {'success': False, 'message': 'æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶'}

        print(f"ğŸ“Š æ‰¾åˆ° {len(image_files)} ä¸ªå›¾ç‰‡æ–‡ä»¶")

        # åˆ›å»ºè¾“å‡ºç›®å½•
        Path(output_dir).mkdir(parents=True, exist_ok=True)

        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„
        output_files = []
        for image_file in image_files:
            image_name = Path(image_file).stem
            output_file = Path(output_dir) / f"{image_name}_baidu.md"
            output_files.append(str(output_file))

        print(f"\nğŸ”„ å¼€å§‹å¤„ç†...")
        print("=" * 60)

        # å¼€å§‹æ‰¹é‡å¤„ç†
        start_time = datetime.now()

        # ä½¿ç”¨è¿›åº¦æ¡æ˜¾ç¤ºå¤„ç†è¿›åº¦
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            futures = []
            for img_file, out_file in zip(image_files, output_files):
                future = executor.submit(self.process_single_image_safe, img_file, out_file)
                futures.append(future)

            # å¤„ç†ç»“æœå¹¶æ˜¾ç¤ºè¿›åº¦
            results = []
            for future in tqdm(concurrent.futures.as_completed(futures),
                              total=len(futures),
                              desc="ç™¾åº¦OCRå¤„ç†è¿›åº¦"):
                result = future.result()
                results.append(result)
                self.processed_count += 1

                # æ¯å¤„ç†10ä¸ªæ–‡ä»¶æ˜¾ç¤ºä¸€æ¬¡ç»Ÿè®¡
                if self.processed_count % 10 == 0:
                    success_rate = (self.success_count / self.processed_count) * 100
                    print(f"\nğŸ“ˆ è¿›åº¦: {self.processed_count}/{len(image_files)} "
                          f"æˆåŠŸç‡: {success_rate:.1f}% "
                          f"({self.success_count}/{self.failed_count})")

        end_time = datetime.now()
        total_time = (end_time - start_time).total_seconds()

        # ç”Ÿæˆæœ€ç»ˆç»Ÿè®¡
        final_stats = {
            'total_files': len(image_files),
            'processed_files': self.processed_count,
            'success_count': self.success_count,
            'failed_count': self.failed_count,
            'success_rate': (self.success_count / len(image_files)) * 100,
            'total_time': total_time,
            'avg_time_per_file': total_time / len(image_files) if image_files else 0,
            'results': results
        }

        print(f"\nğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆ!")
        print("=" * 60)
        print(f"ğŸ“Š ç»Ÿè®¡ç»“æœ:")
        print(f"   æ€»æ–‡ä»¶æ•°: {final_stats['total_files']}")
        print(f"   æˆåŠŸ: {final_stats['success_count']}")
        print(f"   å¤±è´¥: {final_stats['failed_count']}")
        print(f"   æˆåŠŸç‡: {final_stats['success_rate']:.1f}%")
        print(f"   æ€»ç”¨æ—¶: {total_time:.1f}ç§’")
        print(f"   å¹³å‡é€Ÿåº¦: {final_stats['avg_time_per_file']:.2f}ç§’/æ–‡ä»¶")

        return final_stats

    def generate_report(self, stats: Dict, output_dir: str):
        """ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
        report_file = Path(output_dir) / "baidu_ocr_batch_report.md"

        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("# ç™¾åº¦OCRæ‰¹é‡å¤„ç†æŠ¥å‘Š\n\n")
            f.write(f"å¤„ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

            # æ€»ä½“ç»Ÿè®¡
            f.write("## æ€»ä½“ç»Ÿè®¡\n\n")
            f.write(f"- æ€»æ–‡ä»¶æ•°: {stats['total_files']}\n")
            f.write(f"- æˆåŠŸå¤„ç†: {stats['success_count']}\n")
            f.write(f"- å¤„ç†å¤±è´¥: {stats['failed_count']}\n")
            f.write(f"- æˆåŠŸç‡: {stats['success_rate']:.1f}%\n")
            f.write(f"- æ€»ç”¨æ—¶: {stats['total_time']:.1f}ç§’\n")
            f.write(f"- å¹³å‡é€Ÿåº¦: {stats['avg_time_per_file']:.2f}ç§’/æ–‡ä»¶\n\n")

            # æˆæœ¬ä¼°ç®—
            cost_per_request = 0.0015  # å…ƒ
            total_cost = stats['total_files'] * cost_per_request
            f.write(f"- æˆæœ¬ä¼°ç®—: {total_cost:.2f}å…ƒ\n")
            f.write(f"- å…è´¹é¢åº¦: æ¯æ—¥500-1000æ¬¡\n\n")

            # å¤±è´¥æ–‡ä»¶è¯¦æƒ…
            if stats['failed_count'] > 0:
                f.write("## å¤±è´¥æ–‡ä»¶è¯¦æƒ…\n\n")
                failed_results = [r for r in stats['results'] if not r['success']]
                for i, result in enumerate(failed_results[:10], 1):  # æ˜¾ç¤ºå‰10ä¸ªå¤±è´¥æ–‡ä»¶
                    f.write(f"### {i}. {Path(result['image_file']).name}\n")
                    f.write(f"é”™è¯¯ä¿¡æ¯: {result['error']}\n")
                    f.write(f"å¤„ç†æ—¶é—´: {result['processing_time']:.2f}ç§’\n\n")

                if len(failed_results) > 10:
                    f.write(f"... è¿˜æœ‰ {len(failed_results) - 10} ä¸ªå¤±è´¥æ–‡ä»¶\n\n")

            # æˆåŠŸæ–‡ä»¶ç¤ºä¾‹
            success_results = [r for r in stats['results'] if r['success']]
            if success_results:
                f.write("## æˆåŠŸæ–‡ä»¶ç¤ºä¾‹\n\n")
                # é€‰æ‹©å‡ ä¸ªä¸åŒå¤§å°çš„æˆåŠŸæ–‡ä»¶ä½œä¸ºç¤ºä¾‹
                small_file = min(success_results, key=lambda x: x['char_count'])
                large_file = max(success_results, key=lambda x: x['char_count'])
                avg_file = sorted(success_results, key=lambda x: x['char_count'])[len(success_results)//2]

                for example, title in [(small_file, "å°æ–‡ä»¶ç¤ºä¾‹"), (large_file, "å¤§æ–‡ä»¶ç¤ºä¾‹"), (avg_file, "ä¸­ç­‰æ–‡ä»¶ç¤ºä¾‹")]:
                    f.write(f"### {title}\n")
                    f.write(f"æ–‡ä»¶: {Path(example['image_file']).name}\n")
                    f.write(f"å­—ç¬¦æ•°: {example['char_count']}\n")
                    f.write(f"å•è¯æ•°: {example['word_count']}\n")
                    f.write(f"å¤„ç†æ—¶é—´: {example['processing_time']:.2f}ç§’\n\n")

            # è´¨é‡å¯¹æ¯”å»ºè®®
            f.write("## è´¨é‡å¯¹æ¯”å»ºè®®\n\n")
            f.write("ä¸ºäº†å¯¹æ¯”ç™¾åº¦OCRä¸Tesseractçš„æ•ˆæœï¼Œå»ºè®®ï¼š\n\n")
            f.write("1. **éšæœºæŠ½æ ·å¯¹æ¯”**: é€‰æ‹©10-20ä¸ªä¸åŒå†…å®¹çš„å›¾ç‰‡\n")
            f.write("2. **äººå·¥è¯„ä¼°**: å¯¹æ¯”ä¸¤ç§OCRçš„å‡†ç¡®æ€§ã€æ ¼å¼ä¿æŒç­‰\n")
            f.write("3. **å…³æ³¨ä¸­æ–‡å†…å®¹**: é‡ç‚¹å¯¹æ¯”ä¸­æ–‡è¯†åˆ«æ•ˆæœ\n")
            f.write("4. **æ£€æŸ¥è¡¨æ ¼å’Œç‰¹æ®Šæ ¼å¼**: å¯¹æ¯”å¤æ‚å¸ƒå±€çš„å¤„ç†æ•ˆæœ\n\n")

            f.write("## åç»­æ­¥éª¤\n\n")
            f.write("1. å¯¹æ¯”åˆ†æç™¾åº¦OCRä¸åŸå§‹Tesseractç»“æœ\n")
            f.write("2. è¯„ä¼°è´¨é‡æ”¹è¿›æ•ˆæœ\n")
            f.write("3. å†³å®šæ˜¯å¦å…¨é¢é‡‡ç”¨ç™¾åº¦OCR\n")
            f.write("4. å»ºç«‹æœ€ä¼˜OCRå¤„ç†ç­–ç•¥\n\n")

            f.write("---\n")
            f.write("*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {}*\n".format(datetime.now().strftime('%Y-%m-%d %H:%M:%S')))

        print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ç™¾åº¦OCRæ‰¹é‡å¤„ç†å™¨")
    print("=" * 60)

    # APIå‡­æ®
    api_key = "Y5iCqs919ZJP1Og1fEQqGsSW"
    secret_key = "c8La43KW46QInpCD3muLZIdtc1DiKpKa"

    # ç›®æ ‡ç›®å½•
    image_dir = "/Users/lixiangqun/Work/AI Positioning/è€æ¿æ¡ˆä¾‹/æ¡ˆä¾‹ç…§ç‰‡2"
    output_dir = "baidu_ocr_results"

    # åˆå§‹åŒ–å¤„ç†å™¨
    processor = BaiduOCRBatchProcessor(api_key, secret_key)

    # å¼€å§‹æ‰¹é‡å¤„ç†
    stats = processor.process_batch(image_dir, output_dir, max_workers=3)

    # ç”ŸæˆæŠ¥å‘Š
    processor.generate_report(stats, output_dir)

    # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
    print(f"\nğŸ¯ å¤„ç†å®Œæˆ!")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {output_dir}/")
    print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Š: {output_dir}/baidu_ocr_batch_report.md")

    # æé†’å¯¹æ¯”æµ‹è¯•
    print(f"\nğŸ’¡ ä¸‹ä¸€æ­¥å»ºè®®:")
    print(f"1. å¯¹æ¯”ç™¾åº¦OCRç»“æœä¸åŸå§‹Tesseractç»“æœ")
    print(f"2. è¯„ä¼°è´¨é‡æ”¹è¿›æ•ˆæœ")
    print(f"3. é€‰æ‹©æœ€ä¼˜çš„OCRå¤„ç†æ–¹æ¡ˆ")

if __name__ == "__main__":
    main()